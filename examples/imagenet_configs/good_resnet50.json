{
	"baselines.train_path": "/mnt/cfs/datasets/pytorch_imagenet/train",
	"baselines.val_path": "/mnt/cfs/datasets/pytorch_imagenet/val",
	"baselines.use_baseline": 0,
	"data.train_dataset": "/mnt/cfs/home/engstrom/store/ffcv/train_500_0.5_90.ffcv",
	"data.val_dataset": "/mnt/cfs/home/engstrom/store/ffcv/val_500_0.5_90.ffcv",
	"data.num_workers": 10,
	"logging.folder": "/tmp/",
	"training.batch_size": 128,
	"training.optimizer": "sgd",
	"training.lr": 0.275,
	"training.momentum": 0.9,
	"training.weight_decay": 0.0001,
	"training.epochs": 90,
	"training.lr_peak_epoch": 5.0,
	"training.label_smoothing": 0.1,
	"training.distributed": 1,
	"training.mixup_alpha": 0.0,
	"training.mixup_same_lambda": 1,
	"validation.batch_size": 512,
	"validation.resolution": 224,
	"validation.lr_tta": 1,
	"model.arch": "resnet50",
	"model.antialias": 0,
	"resolution.min_res": 160,
	"resolution.max_res": 160,
	"resolution.end_ramp": 0,
	"training.step_ratio": 0.1,
	"training.step_length": 30,
	"training.lr_schedule_type": "step",
	"training.eval_only": 0,
	"training.pretrained": 0,
	"training.bn_wd": 0,
	"dist.world_size": 4,
	"dist.port": "12359"
}
